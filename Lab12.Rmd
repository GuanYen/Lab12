---
title: "Lab12"
author: "Jason Chen"
date: "2024-11-15"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
---

# Task 1
```{r}
  getwd();
```

# Task 2

## NULL Hypotheses
```{r}
  set.seed(55);x1=rnorm(30,mean=25,sd=5)
  result <- t.test(x1,mu=22,conf.level=0.95)
  result$p.value
  result$conf.int
```
$H_0:\mu=22$ is rejected because p-value=0.002 < 0.05 and $22 \notin CI$

```{r}
  result <- t.test(x1,mu=23,conf.level=0.95)
  result$p.value
  result$conf.int
```
$H_0:\mu=23$ is rejected because p-value=0.0025 < 0.05 and $23 \notin CI$

```{r}
  result <- t.test(x1,mu=24,conf.level=0.95)
  result$p.value
  result$conf.int
```
$H_0:\mu=24$ is plausible because p-value=0.19 > 0.05 and $24 \in CI$

```{r}
  result <- t.test(x1,mu=25,conf.level=0.95)
  result$p.value
  result$conf.int
```
$H_0:\mu=25$ is plausible because p-value=0.77 > 0.05 and $25 \in CI$

```{r}
  result <- t.test(x1,mu=26,conf.level=0.95)
  result$p.value
  result$conf.int
```
$H_0:\mu=26$ is plausible because p-value=0.47 > 0.05 and $26 \in CI$

## Boxplot
```{r}
  boxplot(x1, main="Sample x1")
  ci=t.test(x1,mu=23)$conf.int
  ci
  abline(h=c(ci,mean(x1)),col=c("Red","Red","Green"))
```

## p-value
```{r}
  tcalc=(mean(x1)-24)/(sd(x1)/sqrt(30))
  tcalc
  
mypvalue=function(t0,xmax=4,n=20, alpha=0.05){
#calculate alpha/2
va=round(pt(-t0,df=n-1),4)
pv=2*va

# plot the t dist
curve(dt(x,df=n-1),xlim=c(-xmax,xmax),ylab="T Density",xlab=expression(t),
main=substitute(paste("P-value=", pv, " alpha=", alpha)))

# set up points on the polygon to the right
xcurve=seq(t0,xmax,length=1000)
ycurve=dt(xcurve,df=n-1)

# set up points to the left
xlcurve=seq(-t0,-xmax,length=1000)
ylcurve=dt(xcurve,df=n-1)

# Shade in the polygon defined by the line segments
polygon(c(t0,xcurve,xmax),c(0,ycurve,0),col="green")
polygon(c(-t0,xlcurve,-xmax),c(0,ylcurve,0),col="green")

# make quantiles
q=qt(1-alpha/2,n-1)
abline( v=c(q,-q),lwd=2) # plot the cut off t value 
axis(3,c(q,-q),c(expression(abs(t[alpha/2])),expression(-abs(t[alpha/2]))))

# Annotation
text(0.5*(t0+xmax),max(ycurve),substitute(paste(area, "=",va)))
text(-0.5*(t0+xmax),max(ycurve),expression(area))

return(list(q=q,pvalue=pv))
}

  mypvalue(tcalc,n=30,alpha=0.05)
```

The rejection region is when $t \leq 2$ and $t \geq 2$. 

The p-value that determines if we reject $H_0$ or not is 0.05.

$t_calc = 1.326$ which is greater than -2 and less than 2, so it is not in the rejection region.

## Bootstrap p-values
```{r}
bootpval<-function(x,conf.level=0.95,iter=3000,mu0=0, test="two"){
n=length(x)
y=x-mean(x)+mu0  # transform the data so that it is centered at the NULL
rs.mat<-c()    #rs.mat will become a resample matrix -- now it is an empty vector
xrs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
rs.mat<-cbind(rs.mat,sample(y,n,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
xrs.mat<-cbind(xrs.mat,sample(x,n,replace=TRUE)) #sampling from x cbind -- column bind -- binds the vectors together by columns

}

tstat<-function(z){ # The value of t when the NULL is assumed true (xbar-muo)/z/sqrt(n)
sqrt(n)*(mean(z)-mu0)/sd(z)
}

tcalc=tstat(x) # t for the data collected
ytstat=apply(rs.mat,2,tstat) # tstat of resampled y's, ytstat is a vector and will have iter values in it
xstat=apply(xrs.mat,2,mean)  # mean of resampled x's
alpha=1-conf.level # calculating alpha
ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(ytstat[ytstat>abs(tcalc) | ytstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(ytstat[ytstat>tcalc])/iter,
length(ytstat[ytstat<xstat])/iter))

h=hist(ytstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
if(test=="upper"){
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Gray",length(mid)-ncolr),rep("Green",ncolr))
}

if(test=="lower"){
ncoll=length(mid[mid<=  -abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll))
}
hist(ytstat,col=col,freq=FALSE,las=1,main="",xlab=expression(T[stat]))
#segments(ci[1],0,ci[2],0,lwd=2)
pround=round(pvalue,4)
title(substitute(paste(P[value],"=",pround)))
return(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}

  result <- bootpval(x1, conf.level = 0.95, mu0 = 22)
  result
  
  result <- bootpval(x1, conf.level = 0.95, mu0 = 23)
  result
  
  result <- bootpval(x1, conf.level = 0.95, mu0 = 24)
  result
  
  result <- bootpval(x1, conf.level = 0.95, mu0 = 25)
  result
  
  result <- bootpval(x1, conf.level = 0.95, mu0 = 26)
  result
```

The bootstrap p-values are close to the t.test p-values.

# Task 3

## var.test
```{r}
  set.seed(30);x=rnorm(15,mean=10,sd=7)   
  set.seed(40);y=rnorm(20,mean=12,sd=4)
  
  var.test(x,y)
```

The variance of the two samples are not equal because $p-value = 0.01594 \leq 0.05$.

Therefore, var.equal=FALSE inside t.test().

## t.test()
```{r}
  t.test(y, x, mu=0, var.equal = FALSE)
  t.test(y, x, mu=2, var.equal = FALSE)
```

The confidence interval of the two tests are bigger than if the variances are equal. Neither NULL hypotheses can be rejected as implausible.

# Task 4
```{r}
  set.seed(30);x1=rnorm(15,mean=10,sd=4)   
  set.seed(40);y1=rnorm(20,mean=12,sd=4)
  
  var.test(x1,y1)
```

var.equal=TRUE inside t.test().

```{r}
  t.test(y1, x1, mu=0, var.equal = TRUE)
  t.test(y1, x1, mu=2, var.equal = TRUE)
```

The degrees of freedom are integers in this test while in the other one it was a decimal. The confidence intervals are smaller causing $0 \notin CI$, so we can reject the the first NULL hypothesis as implausible.

# Task 5
```{r}
boot2pval<-function(x1,x2,conf.level=0.95,iter=3000,mudiff=0, test="two"){
n1=length(x1)
n2=length(x2)
y1=x1-mean(x1)+mean(c(x1,x2))  # transform the data so that it is centered at the NULL
y2=x2-mean(x2)+mean(c(x1,x2))
y1rs.mat<-c()    #rs.mat will be come a resample matrix -- now it is an empty vector
x1rs.mat<-c()
y2rs.mat<-c()
x2rs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
y1rs.mat<-cbind(y1rs.mat,sample(y1,n1,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
y2rs.mat<-cbind(y2rs.mat,sample(y2,n2,replace=TRUE))

}
x1rs.mat<-y1rs.mat+mean(x1)-mean(c(x1,x2))
x2rs.mat<-y2rs.mat+mean(x2)-mean(c(x1,x2))

xbar1=mean(x1)
xbar2=mean(x2)
sx1sq=var(x1)
sx2sq=var(x2)

tcalc=(xbar1-xbar2-mudiff)/sqrt(sx1sq/n1+sx2sq/n2)

sy1sq=apply(y1rs.mat,2,var)
sy2sq=apply(y2rs.mat,2,var) 
y1bar=apply(y1rs.mat,2,mean)
y2bar=apply(y2rs.mat,2,mean)

tstat=(y1bar-y2bar-mudiff)/sqrt(sy1sq/n1+sy2sq/n2)
ytstat <- NULL

alpha=1-conf.level # calculating alpha
#ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(tstat[tstat>abs(tcalc) | tstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(tstat[tstat>tcalc])/iter,
length(ytstat[tstat<tcalc])/iter))

h=hist(tstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
hist(tstat,col=col,freq=FALSE)
#segments(ci[1],0,ci[2],0,lwd=2)

return(list(pvalue=pvalue))
#return(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}
  
  boot2pval(y,x,mudiff = 0)
  boot2pval(y,x,mudiff = 2)
```

# Task 6
```{r}
  boot2pval(y1,x1,mudiff = 0)
  boot2pval(y1,x1,mudiff = 2)
```

# Task 7

A: Calls t.test on x1 with estimated mean=23. So NULL hypothesis is mean=23.

B: Indicates the t.test performed a one-sample t-test.

C: List containing tstat, degrees of freedom, and p-value.

D: Based on the result of the t.test, reject the NULL hypothesis that is mean=23.

E: Introduces 95% confidence interval of the sample mean 

F: The 95% confidence interval of the sample mean is (23.30198, 27.27320).

G: Based on the results of the t.test, it estimates the mean=25.28759.

# Task 8
```{r}
  set.seed(10);x3=rnorm(15,mean=5,sd=4)   
  set.seed(20);y3=rnorm(20,mean=8,sd=4)
  MATH4753JChen::boot2pval(y3,x3,mudiff = 0)
```












